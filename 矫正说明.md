20180407
1.在 [data_process/embed2ndarray.py](https://github.com/yongyehuang/zhihu-text-classification/blob/master/data_process/embed2ndarray.py#L22) 处理词向量时添加特殊符号数量和添加的随机向量的个数之前没有对齐，现在已经修正。（感谢ziliang学长，感谢山大李永祺同学指出错误）

2.在[data_process/char2id.py 和 data_process/word2id.py](https://github.com/yongyehuang/zhihu-text-classification/blob/master/data_process/char2id.py#L91) 处理中：
```python
# 原本
df_train.loc[na_index, 'char_content'] = df_train.loc[na_index, 'char_title']
# 修改为，提升处理
df_train.at[na_index, 'char_content'] = df_train.at[na_index, 'char_title']

```
(感谢@jefferyship指出)

3.在模型训练的 [train.py 文件中更新embedding的代码](https://github.com/yongyehuang/zhihu-text-classification/blob/master/models/wd_1_1_cnn_concat/train.py#L189) 中，修正之前的错误，现在是当迭代到 FLAGS.max_epoch 时，开始更新embedding，一般 FLAGS.max_epoch 设置为 1 或者 2 都行。（感谢山大李永祺同学指出错） 


由于之前不够熟练，比赛中的代码都是写在 notebook 上面的，比较乱。如果在模型复现的时候出现什么问题，也可以参考[我最初的代码](https://github.com/yongyehuang/zhihu-text-classification/tree/master/notebook-old)，里边有训练时候的输出。

欢迎指正和交流！
